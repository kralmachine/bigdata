{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\toshiba\\\\SkyDrive\\\\veribilimi.co\\\\Datasets\\\\iris.csv\")\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  Iris-setosa\n",
       "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "4  5.4  3.9  1.7  0.4  Iris-setosa"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri setine bakış\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-with</th>\n",
       "      <th>pedal-length</th>\n",
       "      <th>pedal-width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-with  pedal-length  pedal-width        label\n",
       "0           4.9         3.0           1.4          0.2  Iris-setosa\n",
       "1           4.7         3.2           1.3          0.2  Iris-setosa\n",
       "2           4.6         3.1           1.5          0.2  Iris-setosa\n",
       "3           5.0         3.6           1.4          0.2  Iris-setosa\n",
       "4           5.4         3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri setinde sütun isimleri yokmuş. Hadi ekleyelim.\n",
    "iris_cols = ['sepal-length', 'sepal-with', 'pedal-length','pedal-width','label'] \n",
    "dataset.columns = iris_cols\n",
    "\n",
    "# Doğru eklemiş miyiz bakalım:\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bağımlı ve bağımsız değişkenleri ayırma\n",
    "\n",
    "# Python'da sütunların indeks değeri 0'dan başladığından ve 5 sütun olduğundan son niteliğin indeks değeri 4 olacaktır. \n",
    "# iloc ile sütun seçerken ilk değer dahil ikinci değer hariçtir. bu sebeple 0'ı dahil 4'ü hariç tutacağız. \n",
    "# Çünkü son indeks değeri label yani hedef değişkene ait. \n",
    "# iloc[] içindeki İlk iki nokta (:) tüm satırları ifade ederken \",\" sonrası sütunlardan seçilecek filtreyi ifade eder.\n",
    "# 0:4 demek 0 dahil 4 hariç indeksli sütunları seç demek. Yani 0,1,2,3\n",
    "\n",
    "X = dataset.iloc[:,0:4].values\n",
    "\n",
    "# Hedef niteliğimiz 4. indekste idi. O sebeple : ile tüm satırları \",\" den sonra 4 ile hedef niteliğin indeksini seçiyoruz.\n",
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedef Değişkeni Dönüştürmek\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eğitim ve Test Seti olarak Ayırmak\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Sıralamaya dikkat. Aynı sonuçlar için random_state değeri aynı olmalıdır.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nitelikler matrisini (X) StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras kütüphanelerini indirme\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YAPAY SİNİR AĞI NESNESİ OLUŞTURMA\n",
    "# Yapay sinir ağı iki farklı şekilde başlatılabilir: 1. Katmanlar dizilimi (Sequantial layers) olarak. 2. Graph olarak.\n",
    "# Birinci yolda sadece yukarıda indirilen Sequantial sınıfından nesne yaratılır. Bu da Karar ağacı, SVM gibi bir sınıflandırıcı olacak.\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bir Sinir Ağını Stochastic Gradient Descent ile Eğitmenin Aşamaları\n",
    "1. Sıfıra yakın rastgele değerler ile ağırlık katsayılarını belirle.\n",
    "2. Input layera ilk gözlemi(bir satır) her bir düğüme bir nitelik (nitelikler matrisi sütün sayısı kadar) düşecek şekilde ver.\n",
    "3. Ağı çalıştır ve ilk tahmin y değerini üret.\n",
    "4. Üretilen y ile tahmin edilen y arasındaki hatayı hesapla.\n",
    "5. Hesaplanan hatayı geri besleme olarak gönder ve her bir ağırlık katsayısını güncelle.\n",
    "6. 1 ve 5 arasını ya her bir satırdan sonra veya belli bir satır sayısından (grup-batch) sonra tekrarla.\n",
    "7. Veri setindeki tüm satırların bitmesi bir epoch oluşturur. Bunu defalarca tekrarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GİRDİ VE İLK GİZLİ KATMANI EKLEME\n",
    " classifier nesnesinin add() metodu içine Dense() Sınıfının nesnesnesini parametre olarak veriyoruz.\n",
    " Dense içindeki ilk parametre \n",
    " kernel_initializer (eski init): Başlangıç ağırlıklarını belirler. uniform fonksiyonunu kullanıyoruz.\n",
    " input_dim: Yapay sinir ağı nesnesine ilk katman ekleme işlemi yapılırken mutlaka girdi katmanında kaç düğüm olacağı bildirilir.\n",
    " aksi halde ilk gizli katman kendisine kaç düğümden bağlantı olacak bilemez. \n",
    " Bu rakam nitelikler matrisindeki sütun sayısıdır yani 4\n",
    "\n",
    " units (eski:output_dim): Bu sayının nasıl verileceğine dair sağlam bir kural yok. Biraz sanatkarlık ve tecrübe\n",
    " gerektiriyor. Tecrübeye dayalı ipucu: Girdi ve çıktı düğüm sayısının ortalamasını verebilirsin. \n",
    " Bu örnekte (4+3=7/2=3,5 ~ 4) Ya da parametre tuning tekniklerini kullanabilirsin.\n",
    "\n",
    " activation: Gizli düğümler için rectifier çıktı düğüm için softsign olsun. Rectifier action parametresinde relu olarak tanımlı\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(kernel_initializer = 'uniform', input_dim = 4, units = 4,  activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İKİNCİ GİZLİ KATMANI EKLEME\n",
    "\n",
    " İkinci Gizli Katmanı Eklemek\n",
    "\n",
    " Yukarıda ilk gizli katman ve düğüm sayısı belli olduğu için burada input_dim parametresi kullanmaya gerek yok.\n",
    " Gizli katman sayısını (units) aynı tutuyoruz. kaba formül kullandık yine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier.add(Dense(kernel_initializer = 'uniform', units = 4,  activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÇIKTI KATMANI (OUTPUT LAYER) EKLEME\n",
    " Bu katmanın bir öncekinden farkı düğüm sayısı ve activasyon fonksiyonu olacak. Hedef değişken üç farklı değer alacağı için units=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(kernel_initializer = 'uniform', units = 3,  activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer: Stochastic Gradient Descent'i temsilen adam\n",
    "# loss: SGD'ni optimizasyonu için kullanılacak loss function. Tahmin y ile gerçek ye değeri arasını hesaplayıp en optimal değeri\n",
    "# SGD'ye buldurur. Logaritmik loss function. Binary olduğu için categorical_crossentropy kullanıyoruz.\n",
    "# metrics: İlave olarak burada model değerlendirme kriterleri belirlenir. Bir liste halinde verilir. \n",
    "# Biz şimdilik sadece accuracy veriyoruz.\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 1.0985 - acc: 0.3445\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 320us/step - loss: 1.0952 - acc: 0.3697\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 294us/step - loss: 1.0855 - acc: 0.5966\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 277us/step - loss: 1.0663 - acc: 0.6807\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 256us/step - loss: 1.0374 - acc: 0.6639\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 252us/step - loss: 1.0000 - acc: 0.6639\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 252us/step - loss: 0.9565 - acc: 0.6639\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 227us/step - loss: 0.9107 - acc: 0.6639\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 324us/step - loss: 0.8618 - acc: 0.6639\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 294us/step - loss: 0.8155 - acc: 0.6639\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 324us/step - loss: 0.7658 - acc: 0.6723\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 328us/step - loss: 0.7207 - acc: 0.6723\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 315us/step - loss: 0.6820 - acc: 0.6807\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 349us/step - loss: 0.6483 - acc: 0.6891\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 336us/step - loss: 0.6197 - acc: 0.6975\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 311us/step - loss: 0.5958 - acc: 0.6975\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.5744 - acc: 0.7143\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 336us/step - loss: 0.5560 - acc: 0.7143\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 324us/step - loss: 0.5394 - acc: 0.7395\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 290us/step - loss: 0.5247 - acc: 0.7479\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 294us/step - loss: 0.5123 - acc: 0.7563\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 244us/step - loss: 0.4990 - acc: 0.7563\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 227us/step - loss: 0.4887 - acc: 0.7731\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 244us/step - loss: 0.4778 - acc: 0.7899\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 265us/step - loss: 0.4682 - acc: 0.7899\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 286us/step - loss: 0.4593 - acc: 0.7899\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 286us/step - loss: 0.4508 - acc: 0.7899\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 269us/step - loss: 0.4426 - acc: 0.7899\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 248us/step - loss: 0.4347 - acc: 0.7983\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 282us/step - loss: 0.4280 - acc: 0.7983\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 261us/step - loss: 0.4203 - acc: 0.8067\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 370us/step - loss: 0.4136 - acc: 0.8067\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 320us/step - loss: 0.4072 - acc: 0.7983\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 349us/step - loss: 0.4005 - acc: 0.7983\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 345us/step - loss: 0.3944 - acc: 0.8067\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 278us/step - loss: 0.3887 - acc: 0.8235\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 277us/step - loss: 0.3829 - acc: 0.8235\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 307us/step - loss: 0.3771 - acc: 0.8403\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 319us/step - loss: 0.3710 - acc: 0.8487\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 320us/step - loss: 0.3656 - acc: 0.8487\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 286us/step - loss: 0.3598 - acc: 0.8487\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 303us/step - loss: 0.3539 - acc: 0.8655\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 345us/step - loss: 0.3484 - acc: 0.8655\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 362us/step - loss: 0.3430 - acc: 0.8655\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 336us/step - loss: 0.3377 - acc: 0.8655\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 362us/step - loss: 0.3323 - acc: 0.8655\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 336us/step - loss: 0.3274 - acc: 0.8739\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 307us/step - loss: 0.3221 - acc: 0.8739\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 303us/step - loss: 0.3172 - acc: 0.8824\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.3127 - acc: 0.8824\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 294us/step - loss: 0.3082 - acc: 0.8824\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 320us/step - loss: 0.3030 - acc: 0.8992\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 328us/step - loss: 0.2985 - acc: 0.8992\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 303us/step - loss: 0.2939 - acc: 0.8992\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 307us/step - loss: 0.2893 - acc: 0.9076\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 324us/step - loss: 0.2852 - acc: 0.9076\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.2810 - acc: 0.9076\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 265us/step - loss: 0.2768 - acc: 0.9076\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 256us/step - loss: 0.2728 - acc: 0.9076\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 290us/step - loss: 0.2682 - acc: 0.9076\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 282us/step - loss: 0.2643 - acc: 0.9244\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 244us/step - loss: 0.2604 - acc: 0.9328\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 240us/step - loss: 0.2577 - acc: 0.9328\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 282us/step - loss: 0.2525 - acc: 0.9328\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 256us/step - loss: 0.2493 - acc: 0.9328\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 278us/step - loss: 0.2455 - acc: 0.9328\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 265us/step - loss: 0.2418 - acc: 0.9328\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 261us/step - loss: 0.2381 - acc: 0.9412\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 248us/step - loss: 0.2349 - acc: 0.9412\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 286us/step - loss: 0.2310 - acc: 0.9496\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 328us/step - loss: 0.2275 - acc: 0.9496\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 345us/step - loss: 0.2244 - acc: 0.9496\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 320us/step - loss: 0.2213 - acc: 0.9496\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 294us/step - loss: 0.2177 - acc: 0.9496\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 303us/step - loss: 0.2146 - acc: 0.9496\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 307us/step - loss: 0.2117 - acc: 0.9496\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 341us/step - loss: 0.2081 - acc: 0.9496\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 328us/step - loss: 0.2052 - acc: 0.9496\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 341us/step - loss: 0.2030 - acc: 0.9496\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 256us/step - loss: 0.1992 - acc: 0.9496\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 223us/step - loss: 0.1965 - acc: 0.9496\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 231us/step - loss: 0.1939 - acc: 0.9496\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 294us/step - loss: 0.1911 - acc: 0.9496\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 341us/step - loss: 0.1883 - acc: 0.9496\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 345us/step - loss: 0.1857 - acc: 0.9580\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 324us/step - loss: 0.1831 - acc: 0.9580\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 261us/step - loss: 0.1803 - acc: 0.9580\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 231us/step - loss: 0.1778 - acc: 0.9580\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.1755 - acc: 0.9580\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 265us/step - loss: 0.1727 - acc: 0.9580\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 273us/step - loss: 0.1703 - acc: 0.9580\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 349us/step - loss: 0.1680 - acc: 0.9580\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.1656 - acc: 0.9580\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 278us/step - loss: 0.1638 - acc: 0.9580\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 231us/step - loss: 0.1611 - acc: 0.9580\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 299us/step - loss: 0.1588 - acc: 0.9580\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 261us/step - loss: 0.1568 - acc: 0.9580\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 248us/step - loss: 0.1546 - acc: 0.9580\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 269us/step - loss: 0.1529 - acc: 0.9580\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 315us/step - loss: 0.1503 - acc: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227f5275630>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred.round(), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
