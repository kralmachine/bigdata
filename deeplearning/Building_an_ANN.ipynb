{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bölüm 1 Hazırlık\n",
    "\n",
    "# Kütüphaneleri İndirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veriyi Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\toshiba\\\\SkyDrive\\\\veribilimi.co\\\\Datasets\\\\Udemy_A_Z_Deep_Learning\\\\Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri setine bakış\n",
    "dataset.head()\n",
    "\n",
    "# Exited hedef değişken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bağımlı ve bağımsız değişkenleri ayırma\n",
    "# RowNumber, CustomerId, Surname hedef değişkeni tahmin etme bakımından işe yaramaz. Bu yüzden 0,1,2 indeksli nitelikleri\n",
    "# Nitelikler matrisine dahil etmiyoruz. Yukarıda kaç tane nitelik olduğunu yazdırmıştık. Şimdi 0,1,2 hari ise 3'ten başlayacak. \n",
    "# Python'da indeks değeri 0'dan başladığına ve 14 nitalik olduğuna göre son niteliğin indeks değeri 13 olacaktır. iloc ile sütun\n",
    "#seçerken ilk değer dahil ikinci değer hariçtir. bu sebeple 3'ü dahil 13'ü hariç tutacağız. Çünkü son indeks değeri Exited yani\n",
    "# hedef değişkene geliyor. İlk : tüm satırlar \",\" sonrası sütunlardan seçilecek filtre. 3:13 demek 3 dahil 13 hariç indeksli\n",
    "# sütunları seç demek\n",
    "\n",
    "X = dataset.iloc[:,3:13].values\n",
    "\n",
    "# Hedef niteliğimiz 13. indekste idi. O sebeple : ile tüm satırları \",\" den sonra 13 ile hedef niteliğin indeksini seçiyoruz.\n",
    "y = dataset.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Veri setini eğitim ve test olarak bölmeden önce mutlaka kategorik nitelikleri halletmek gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedef nitelik 0 ve 1 olmak üzere zaten nümerik değer olduğu için onu LabelEncoder ile kodlamaya gerek yok.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# X nitelikler matrisini incelediğimizde 1'inci indekste Geography 2'nci indekste Gender'ın kategorik olduğunu görüyoruz.\n",
    "# Önce Geagraphy için LabelEncoder yaratalım\n",
    "labelEncoder_Geo = LabelEncoder()\n",
    "X[:, 1] = labelEncoder_Geo.fit_transform(X[:, 1])\n",
    "\n",
    "# Şimdi Gender için\n",
    "labelEncoder_Gender = LabelEncoder()\n",
    "X[:,2] = labelEncoder_Gender.fit_transform(X[:,2])\n",
    "\n",
    "# Gender binary olduğu için onu oneHot yapmaya gerek yok. Ancak Geography üç değerli olduğu için onu oneHot (Gölge değişken)\n",
    "# yapmalıyız. Bunun için OneHotEncoder sınıfını kullanacağız.\n",
    "# Nesneyi oluşturalım ve dönüştüreceğimiz sütunların indeksinden oluşan listeyi parametre verelim. Burada sadece [1] çünkü\n",
    "# tek bir tane \n",
    "oneHotEncoder = OneHotEncoder(categorical_features=[1])\n",
    "\n",
    "# nesnemizin fit_transform() metodunu kullanarak Geography niteliğini gölge değişkenlere çeviriyoruz ve X'e ekliyoruz.\n",
    "X = oneHotEncoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gölge Değişken Tuzağından kurtulmak için Yeni oluşturulan gölge değişkenlerden birini çıkaralım\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eğitim ve Test Seti olarak Ayırmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Sıralamaya dikkat. Aynı sonuçlar için random_state değeri aynı olmalıdır.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nitelikler matrisini (X) StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ..., \n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bölüm 2 ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras kütüphanelerini indirme\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAPAY SİNİR AĞI NESNESİ OLUŞTURMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yapay sinir ağı iki farklı şekilde başlatılabilir: 1. Katmanlar dizilimi (Sequantial layers) olarak. 2. Graph olarak.\n",
    "# Birinci yolda sadece yukarıda indirilen Sequantial sınıfından nesne yaratılır. Bu da Karar ağacı, SVM gibi bir sınıflandırıcı olacak.\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bir Sinir Ağını Stochastic Gradient Descent ile Eğitmenin Aşamaları"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sıfıra yakın rastgele değerler ile ağırlık katsayılarını belirle.\n",
    "2. Input layera ilk gözlemi(bir satır) her bir düğüme bir nitelik (nitelikler matrisi sütün sayısı kadar) düşecek şekilde ver.\n",
    "3. Ağı çalıştır ve ilk tahmin y değerini üret.\n",
    "4. Üretilen y ile tahmin edilen y arasındaki hatayı hesapla.\n",
    "5. Hesaplanan hatayı geri besleme olarak gönder ve her bir ağırlık katsayısını güncelle.\n",
    "6. 1 ve 5 arasını ya her bir satırdan sonra veya belli bir satır sayısından (grup-batch) sonra tekrarla.\n",
    "7. Veri setindeki tüm satırların bitmesi bir epoch oluşturur. Bunu defalarca tekrarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GİRDİ VE İLK GİZLİ KATMANI EKLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier nesnesinin add() metodu içine Dense() Sınıfının nesnesnesini parametre olarak veriyoruz.\n",
    "# Dense içindeki ilk parametre \n",
    "# kernel_initializer (eski init): Başlangıç ağırlıklarını belirler. uniform fonksiyonunu kullanıyoruz.\n",
    "# input_dim: Yapay sinir ağı nesnesine ilk katman ekleme işlemi yapılırken mutlaka girdi katmanında kaç düğüm olacağı bildirilir.\n",
    "# aksi halde ilk gizli katman kendisine kaç düğümden bağlantı olacak bilemez. \n",
    "# Bu rakam nitelikler matrisindeki sütun sayısıdır yani 11\n",
    "# units (eski:output_dim): Bu sayının nasıl verileceğine dair sağlam bir kural yok. Biraz sanatkarlık ve tecrübe\n",
    "# gerektiriyor. Tecrübeye dayalı ipucu: Girdi ve çıktı düğüm sayısının ortalamasını verebilirsin. \n",
    "# Bu örnekte (11+1=12/2=6) Ya da parametre tuning tekniklerini kullanabilirsin.\n",
    "# activation: Gizli düğümler için rectifier çıktı düğüm için sigmoid olsun. Rectifier action parametresinde relu olarak tanımlı\n",
    "\n",
    "\n",
    "classifier.add(Dense(kernel_initializer = 'uniform', input_dim = 11, units = 6,  activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İKİNCİ GİZLİ KATMANI EKLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# İkinci Gizli Katmanı Eklemek\n",
    "\n",
    "# Yukarıda ilk gizli katman ve düğüm sayısı belli olduğu için burada input_dim parametresi kullanmaya gerek yok.\n",
    "# Gizli katman sayısını (units) aynı tutuyoruz. kaba formül kullandık yine.\n",
    "classifier.add(Dense(kernel_initializer = 'uniform', units = 4,  activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÇIKTI KATMANI (OUTPUT LAYER) EKLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bu katmanın bir öncekinden farkı düğüm sayısı ve activasyon fonksiyonu olacak\n",
    "\n",
    "classifier.add(Dense(kernel_initializer = 'uniform', units = 1,  activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAPAY SINIR AĞINI DERLEME (COMPILE ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer: Stochastic Gradient Descent'i temsilen adam\n",
    "# loss: SGD'ni optimizasyonu için kullanılacak loss function. Tahmin y ile gerçek ye değeri arasını hesaplayıp en optimal değeri\n",
    "# SGD'ye buldurur. Logaritmik loss function. Binary olduğu için binary_crossentropy kullanıyoruz.\n",
    "# metrics: İlave olarak burada model değerlendirme kriterleri belirlenir. Bir liste halinde verilir. Biz şimdilik sadece accuracy veriyoruz.\n",
    "\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağını Eğitim Verisi ile Eğitmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 3s 353us/step - loss: 0.4026 - acc: 0.8336\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.4008 - acc: 0.8355\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 3s 369us/step - loss: 0.4006 - acc: 0.8341\n",
      "Epoch 4/200\n",
      "8000/8000 [==============================] - 3s 345us/step - loss: 0.4013 - acc: 0.8355\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 3s 353us/step - loss: 0.4008 - acc: 0.8350\n",
      "Epoch 6/200\n",
      "8000/8000 [==============================] - 3s 343us/step - loss: 0.4011 - acc: 0.8346\n",
      "Epoch 7/200\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.4001 - acc: 0.8354\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.4007 - acc: 0.8359\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.4010 - acc: 0.8345\n",
      "Epoch 10/200\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.4004 - acc: 0.8349\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 3s 396us/step - loss: 0.4011 - acc: 0.8341\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 0.4008 - acc: 0.8373\n",
      "Epoch 13/200\n",
      "8000/8000 [==============================] - 3s 377us/step - loss: 0.4010 - acc: 0.8344\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 3s 373us/step - loss: 0.4004 - acc: 0.8350\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 3s 362us/step - loss: 0.4009 - acc: 0.8335\n",
      "Epoch 16/200\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.4010 - acc: 0.8349\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.4013 - acc: 0.8360\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 3s 346us/step - loss: 0.4011 - acc: 0.8333\n",
      "Epoch 19/200\n",
      "8000/8000 [==============================] - 3s 351us/step - loss: 0.4001 - acc: 0.8348\n",
      "Epoch 20/200\n",
      "8000/8000 [==============================] - 3s 365us/step - loss: 0.4007 - acc: 0.8354\n",
      "Epoch 21/200\n",
      "8000/8000 [==============================] - 3s 343us/step - loss: 0.4012 - acc: 0.8348\n",
      "Epoch 22/200\n",
      "8000/8000 [==============================] - 3s 315us/step - loss: 0.4008 - acc: 0.8350\n",
      "Epoch 23/200\n",
      "8000/8000 [==============================] - 3s 323us/step - loss: 0.4009 - acc: 0.8355\n",
      "Epoch 24/200\n",
      "8000/8000 [==============================] - 3s 326us/step - loss: 0.4006 - acc: 0.8345\n",
      "Epoch 25/200\n",
      "8000/8000 [==============================] - 3s 319us/step - loss: 0.4010 - acc: 0.8338\n",
      "Epoch 26/200\n",
      "8000/8000 [==============================] - 3s 321us/step - loss: 0.4002 - acc: 0.8353\n",
      "Epoch 27/200\n",
      "8000/8000 [==============================] - 3s 336us/step - loss: 0.4004 - acc: 0.8370\n",
      "Epoch 28/200\n",
      "8000/8000 [==============================] - 3s 326us/step - loss: 0.4006 - acc: 0.8341\n",
      "Epoch 29/200\n",
      "8000/8000 [==============================] - 3s 349us/step - loss: 0.4009 - acc: 0.8355\n",
      "Epoch 30/200\n",
      "8000/8000 [==============================] - 3s 347us/step - loss: 0.4004 - acc: 0.8345\n",
      "Epoch 31/200\n",
      "8000/8000 [==============================] - 3s 326us/step - loss: 0.4010 - acc: 0.8343\n",
      "Epoch 32/200\n",
      "8000/8000 [==============================] - 3s 364us/step - loss: 0.4003 - acc: 0.8350\n",
      "Epoch 33/200\n",
      "8000/8000 [==============================] - 3s 352us/step - loss: 0.4001 - acc: 0.8343\n",
      "Epoch 34/200\n",
      "8000/8000 [==============================] - 3s 373us/step - loss: 0.4002 - acc: 0.8329\n",
      "Epoch 35/200\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.4006 - acc: 0.8341\n",
      "Epoch 36/200\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 0.4007 - acc: 0.8356\n",
      "Epoch 37/200\n",
      "8000/8000 [==============================] - 3s 350us/step - loss: 0.4006 - acc: 0.8346\n",
      "Epoch 38/200\n",
      "8000/8000 [==============================] - 3s 393us/step - loss: 0.4014 - acc: 0.8349\n",
      "Epoch 39/200\n",
      "8000/8000 [==============================] - 3s 393us/step - loss: 0.3998 - acc: 0.8333\n",
      "Epoch 40/200\n",
      "8000/8000 [==============================] - 3s 383us/step - loss: 0.4006 - acc: 0.8345\n",
      "Epoch 41/200\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.4001 - acc: 0.8354\n",
      "Epoch 42/200\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.4008 - acc: 0.8346\n",
      "Epoch 43/200\n",
      "8000/8000 [==============================] - 3s 327us/step - loss: 0.4002 - acc: 0.8355\n",
      "Epoch 44/200\n",
      "8000/8000 [==============================] - 3s 351us/step - loss: 0.4007 - acc: 0.8343\n",
      "Epoch 45/200\n",
      "8000/8000 [==============================] - 3s 360us/step - loss: 0.4006 - acc: 0.8348\n",
      "Epoch 46/200\n",
      "8000/8000 [==============================] - 3s 333us/step - loss: 0.4000 - acc: 0.8334\n",
      "Epoch 47/200\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.4008 - acc: 0.8356\n",
      "Epoch 48/200\n",
      "8000/8000 [==============================] - 3s 316us/step - loss: 0.4003 - acc: 0.8341\n",
      "Epoch 49/200\n",
      "8000/8000 [==============================] - 3s 317us/step - loss: 0.4003 - acc: 0.8350\n",
      "Epoch 50/200\n",
      "8000/8000 [==============================] - 3s 321us/step - loss: 0.3998 - acc: 0.8363\n",
      "Epoch 51/200\n",
      "8000/8000 [==============================] - 3s 351us/step - loss: 0.3999 - acc: 0.8353\n",
      "Epoch 52/200\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3991 - acc: 0.8363\n",
      "Epoch 53/200\n",
      "8000/8000 [==============================] - 3s 360us/step - loss: 0.3998 - acc: 0.8363\n",
      "Epoch 54/200\n",
      "8000/8000 [==============================] - 3s 327us/step - loss: 0.3985 - acc: 0.8356\n",
      "Epoch 55/200\n",
      "8000/8000 [==============================] - 2s 293us/step - loss: 0.3984 - acc: 0.8350\n",
      "Epoch 56/200\n",
      "8000/8000 [==============================] - 2s 290us/step - loss: 0.3972 - acc: 0.8363\n",
      "Epoch 57/200\n",
      "8000/8000 [==============================] - 2s 281us/step - loss: 0.3984 - acc: 0.8356\n",
      "Epoch 58/200\n",
      "8000/8000 [==============================] - 2s 281us/step - loss: 0.3981 - acc: 0.8364\n",
      "Epoch 59/200\n",
      "8000/8000 [==============================] - 2s 266us/step - loss: 0.3975 - acc: 0.8370\n",
      "Epoch 60/200\n",
      "8000/8000 [==============================] - 2s 293us/step - loss: 0.3972 - acc: 0.8370\n",
      "Epoch 61/200\n",
      "8000/8000 [==============================] - 3s 334us/step - loss: 0.3961 - acc: 0.8356\n",
      "Epoch 62/200\n",
      "8000/8000 [==============================] - 2s 269us/step - loss: 0.3965 - acc: 0.8389 1s - loss: 0\n",
      "Epoch 63/200\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.3964 - acc: 0.8356\n",
      "Epoch 64/200\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3965 - acc: 0.8350\n",
      "Epoch 65/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3951 - acc: 0.8360\n",
      "Epoch 66/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3959 - acc: 0.8365\n",
      "Epoch 67/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3958 - acc: 0.8358\n",
      "Epoch 68/200\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.3953 - acc: 0.8359\n",
      "Epoch 69/200\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3962 - acc: 0.8370\n",
      "Epoch 70/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3953 - acc: 0.8374\n",
      "Epoch 71/200\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3957 - acc: 0.8386\n",
      "Epoch 72/200\n",
      "8000/8000 [==============================] - 2s 201us/step - loss: 0.3948 - acc: 0.8375\n",
      "Epoch 73/200\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3948 - acc: 0.8370\n",
      "Epoch 74/200\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.3945 - acc: 0.8371\n",
      "Epoch 75/200\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3944 - acc: 0.8381\n",
      "Epoch 76/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3943 - acc: 0.8379\n",
      "Epoch 77/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3938 - acc: 0.8361\n",
      "Epoch 78/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3947 - acc: 0.8373 0s - loss: 0.3956 - \n",
      "Epoch 79/200\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3944 - acc: 0.8368\n",
      "Epoch 80/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3940 - acc: 0.8370\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.3942 - acc: 0.8376\n",
      "Epoch 82/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3946 - acc: 0.8348\n",
      "Epoch 83/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3941 - acc: 0.8351\n",
      "Epoch 84/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3941 - acc: 0.8380\n",
      "Epoch 85/200\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.3932 - acc: 0.8368\n",
      "Epoch 86/200\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3936 - acc: 0.8370\n",
      "Epoch 87/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3938 - acc: 0.8381\n",
      "Epoch 88/200\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3935 - acc: 0.8364\n",
      "Epoch 89/200\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3940 - acc: 0.8394\n",
      "Epoch 90/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3943 - acc: 0.8383\n",
      "Epoch 91/200\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.3935 - acc: 0.8383\n",
      "Epoch 92/200\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3931 - acc: 0.8366\n",
      "Epoch 93/200\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3935 - acc: 0.8370\n",
      "Epoch 94/200\n",
      "8000/8000 [==============================] - 2s 252us/step - loss: 0.3942 - acc: 0.8379\n",
      "Epoch 95/200\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3942 - acc: 0.8360\n",
      "Epoch 96/200\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.3938 - acc: 0.8383\n",
      "Epoch 97/200\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.3944 - acc: 0.8368\n",
      "Epoch 98/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3938 - acc: 0.8371\n",
      "Epoch 99/200\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.3932 - acc: 0.8379\n",
      "Epoch 100/200\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.3937 - acc: 0.8384\n",
      "Epoch 101/200\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.3932 - acc: 0.8385\n",
      "Epoch 102/200\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3944 - acc: 0.8385\n",
      "Epoch 103/200\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.3932 - acc: 0.8371\n",
      "Epoch 104/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3932 - acc: 0.8391\n",
      "Epoch 105/200\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.3932 - acc: 0.8350\n",
      "Epoch 106/200\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3929 - acc: 0.8371\n",
      "Epoch 107/200\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3933 - acc: 0.8375\n",
      "Epoch 108/200\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.3934 - acc: 0.8359\n",
      "Epoch 109/200\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3933 - acc: 0.8380 1s - los\n",
      "Epoch 110/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3928 - acc: 0.8380\n",
      "Epoch 111/200\n",
      "8000/8000 [==============================] - 2s 201us/step - loss: 0.3931 - acc: 0.8386 0s - loss: 0.3935 - acc: \n",
      "Epoch 112/200\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.3933 - acc: 0.8376 1s - \n",
      "Epoch 113/200\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3927 - acc: 0.8381\n",
      "Epoch 114/200\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.3922 - acc: 0.8398\n",
      "Epoch 115/200\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3909 - acc: 0.8394\n",
      "Epoch 116/200\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3895 - acc: 0.8424\n",
      "Epoch 117/200\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3874 - acc: 0.8444\n",
      "Epoch 118/200\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3792 - acc: 0.8470\n",
      "Epoch 119/200\n",
      "8000/8000 [==============================] - 2s 269us/step - loss: 0.3603 - acc: 0.8553\n",
      "Epoch 120/200\n",
      "8000/8000 [==============================] - 2s 276us/step - loss: 0.3501 - acc: 0.8593\n",
      "Epoch 121/200\n",
      "8000/8000 [==============================] - 2s 260us/step - loss: 0.3483 - acc: 0.8596\n",
      "Epoch 122/200\n",
      "8000/8000 [==============================] - 2s 251us/step - loss: 0.3471 - acc: 0.8600\n",
      "Epoch 123/200\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3462 - acc: 0.8599\n",
      "Epoch 124/200\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.3459 - acc: 0.8609\n",
      "Epoch 125/200\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.3453 - acc: 0.8610\n",
      "Epoch 126/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3442 - acc: 0.8606\n",
      "Epoch 127/200\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3441 - acc: 0.8611\n",
      "Epoch 128/200\n",
      "8000/8000 [==============================] - 2s 273us/step - loss: 0.3441 - acc: 0.8605\n",
      "Epoch 129/200\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.3433 - acc: 0.8614\n",
      "Epoch 130/200\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.3429 - acc: 0.8585\n",
      "Epoch 131/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3410 - acc: 0.8599\n",
      "Epoch 132/200\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3413 - acc: 0.8596\n",
      "Epoch 133/200\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3407 - acc: 0.8611\n",
      "Epoch 134/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3395 - acc: 0.8620\n",
      "Epoch 135/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3387 - acc: 0.8615\n",
      "Epoch 136/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3389 - acc: 0.8601\n",
      "Epoch 137/200\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3386 - acc: 0.8615\n",
      "Epoch 138/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3383 - acc: 0.8633\n",
      "Epoch 139/200\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3387 - acc: 0.8606\n",
      "Epoch 140/200\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.3383 - acc: 0.8618\n",
      "Epoch 141/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3377 - acc: 0.8630\n",
      "Epoch 142/200\n",
      "8000/8000 [==============================] - 2s 201us/step - loss: 0.3385 - acc: 0.8619\n",
      "Epoch 143/200\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.3373 - acc: 0.8615\n",
      "Epoch 144/200\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3371 - acc: 0.8619\n",
      "Epoch 145/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3360 - acc: 0.8626\n",
      "Epoch 146/200\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3365 - acc: 0.8601\n",
      "Epoch 147/200\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3368 - acc: 0.8630\n",
      "Epoch 148/200\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.3362 - acc: 0.8611\n",
      "Epoch 149/200\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.3358 - acc: 0.8613\n",
      "Epoch 150/200\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.3361 - acc: 0.8620\n",
      "Epoch 151/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3365 - acc: 0.8615\n",
      "Epoch 152/200\n",
      "8000/8000 [==============================] - 2s 255us/step - loss: 0.3367 - acc: 0.8619\n",
      "Epoch 153/200\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.3358 - acc: 0.8610\n",
      "Epoch 154/200\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3358 - acc: 0.8631\n",
      "Epoch 155/200\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3363 - acc: 0.8621\n",
      "Epoch 156/200\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.3363 - acc: 0.8591\n",
      "Epoch 157/200\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3360 - acc: 0.8616\n",
      "Epoch 158/200\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3363 - acc: 0.8593\n",
      "Epoch 159/200\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.3353 - acc: 0.8619\n",
      "Epoch 160/200\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.3359 - acc: 0.8625\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.3355 - acc: 0.8623\n",
      "Epoch 162/200\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 0.3355 - acc: 0.8614\n",
      "Epoch 163/200\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.3355 - acc: 0.8601\n",
      "Epoch 164/200\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.3354 - acc: 0.8614\n",
      "Epoch 165/200\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.3352 - acc: 0.8623\n",
      "Epoch 166/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3342 - acc: 0.8641\n",
      "Epoch 167/200\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3348 - acc: 0.8619\n",
      "Epoch 168/200\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.3347 - acc: 0.8626\n",
      "Epoch 169/200\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3346 - acc: 0.8644\n",
      "Epoch 170/200\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3338 - acc: 0.8643\n",
      "Epoch 171/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3339 - acc: 0.8654\n",
      "Epoch 172/200\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.3339 - acc: 0.8645\n",
      "Epoch 173/200\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3341 - acc: 0.8636\n",
      "Epoch 174/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3342 - acc: 0.8640\n",
      "Epoch 175/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3330 - acc: 0.8628\n",
      "Epoch 176/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3332 - acc: 0.8625\n",
      "Epoch 177/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3328 - acc: 0.8649\n",
      "Epoch 178/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3334 - acc: 0.8650\n",
      "Epoch 179/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3320 - acc: 0.8646\n",
      "Epoch 180/200\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 0.3337 - acc: 0.8624 0s - loss: 0.3338 - acc: 0.861 - ETA: 0s - loss: 0.3356 - acc\n",
      "Epoch 181/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3336 - acc: 0.8656\n",
      "Epoch 182/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3335 - acc: 0.8633\n",
      "Epoch 183/200\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3327 - acc: 0.8638\n",
      "Epoch 184/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3323 - acc: 0.8651\n",
      "Epoch 185/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3330 - acc: 0.8636\n",
      "Epoch 186/200\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3324 - acc: 0.8643 0s - loss: \n",
      "Epoch 187/200\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.3332 - acc: 0.8618\n",
      "Epoch 188/200\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.3323 - acc: 0.8656\n",
      "Epoch 189/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3329 - acc: 0.8644\n",
      "Epoch 190/200\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.3330 - acc: 0.8641\n",
      "Epoch 191/200\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3316 - acc: 0.8649\n",
      "Epoch 192/200\n",
      "8000/8000 [==============================] - 2s 197us/step - loss: 0.3335 - acc: 0.8638\n",
      "Epoch 193/200\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.3322 - acc: 0.8631\n",
      "Epoch 194/200\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3330 - acc: 0.8646\n",
      "Epoch 195/200\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.3323 - acc: 0.8641\n",
      "Epoch 196/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3330 - acc: 0.8634\n",
      "Epoch 197/200\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.3324 - acc: 0.8645\n",
      "Epoch 198/200\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.3328 - acc: 0.8644\n",
      "Epoch 199/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3321 - acc: 0.8660\n",
      "Epoch 200/200\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3329 - acc: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d00fe42e80>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=5, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağını Test verisi ile Test Etmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15685318],\n",
       "       [ 0.34320474],\n",
       "       [ 0.12867427],\n",
       "       ..., \n",
       "       [ 0.1573104 ],\n",
       "       [ 0.14910083],\n",
       "       [ 0.07817345]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of binary and continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-8bdb54799a50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\toshiba\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\toshiba\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[1;32m---> 82\u001b[1;33m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't handle mix of binary and continuous"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387581372058087"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elle accuracy tekrar hesaplayalım (Doğru tahmin edilenlerin tüm test setine oranı)\n",
    "acc = (1556+119)/(1556+39+286+116)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
